wandb: Currently logged in as: mcstewe. Use `wandb login --relogin` to force relogin
<frozen importlib._bootstrap>:228: RuntimeWarning: to-Python converter for std::pair<double, double> already registered; second conversion method ignored.
/home/steve.azzolin/anaconda3/envs/digress/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
CONFIG:
{'general': {'name': 'sbm_200', 'wandb': 'offline', 'gpus': 1, 'resume': None, 'test_only': '/home/steve.azzolin/DiGress_fork/checkpoints/checkpoint_sbm.ckpt', 'sample_bigger_graphs': 200, 'check_val_every_n_epochs': 5, 'sample_every_val': 4, 'val_check_interval': None, 'samples_to_generate': 512, 'samples_to_save': 20, 'chains_to_save': 1, 'log_every_steps': 50, 'number_chain_steps': 50, 'final_model_samples_to_generate': 10000, 'final_model_samples_to_save': 30, 'final_model_chains_to_save': 20, 'evaluate_all_checkpoints': False}, 'model': {'type': 'discrete', 'transition': 'marginal', 'model': 'graph_tf', 'diffusion_steps': 500, 'diffusion_noise_schedule': 'cosine', 'n_layers': 5, 'extra_features': 'all', 'hidden_mlp_dims': {'X': 256, 'E': 128, 'y': 128}, 'hidden_dims': {'dx': 256, 'de': 64, 'dy': 64, 'n_head': 8, 'dim_ffX': 256, 'dim_ffE': 128, 'dim_ffy': 128}, 'lambda_train': [5, 0]}, 'train': {'n_epochs': 1000, 'batch_size': 32, 'lr': 0.0002, 'clip_grad': None, 'save_model': True, 'num_workers': 0, 'ema_decay': 0, 'progress_bar': False, 'weight_decay': 1e-12, 'optimizer': 'adamw', 'seed': 0}, 'dataset': {'name': 'sbm', 'remove_h': None, 'datadir': 'data/sbm/'}}
Marginal distribution of the classes: tensor([1.]) for nodes, tensor([0.9156, 0.0844]) for edges
Marginal distribution of the classes: tensor([1.]) for nodes, tensor([0.9156, 0.0844]) for edges
Multiprocessing is handled by SLURM.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Restoring states from the checkpoint path at /home/steve.azzolin/DiGress_fork/checkpoints/checkpoint_sbm.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from checkpoint at /home/steve.azzolin/DiGress_fork/checkpoints/checkpoint_sbm.ckpt
wandb: Currently logged in as: mcstewe. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in /home/steve.azzolin/DiGress_fork/wandb/run-20230726_101214-6954g21b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sbm_200_resume
wandb: ‚≠êÔ∏è View project at https://wandb.ai/mcstewe/graph_ddm_sbm
wandb: üöÄ View run at https://wandb.ai/mcstewe/graph_ddm_sbm/runs/6954g21b
/home/steve.azzolin/anaconda3/envs/digress/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric SumExceptBatchMetric was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.
  warnings.warn(*args, **kwargs)
Starting test...
Epoch 49499: Test NLL 4891.84 -- Test Atom type KL 0.00 --  Test Edge type KL: 4.86
Test loss: 4891.8374
Samples left to generate: 40/40<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: normalized_laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.
/home/steve.azzolin/DiGress_fork/src/analysis/visualization.py:182: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
Visualizing chains...
1/20 complete2/20 complete3/20 complete4/20 complete5/20 complete6/20 complete7/20 complete8/20 complete9/20 complete10/20 complete11/20 complete12/20 complete13/20 complete14/20 complete15/20 complete16/20 complete17/20 complete18/20 complete19/20 complete20/20 complete
Visualizing molecules...
Done.
Samples left to generate: 16/40/home/steve.azzolin/DiGress_fork/src/analysis/spectre_utils.py:613: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.
  adj = nx.adjacency_matrix(G).toarray()
Visualizing chains...

Visualizing molecules...
Done.
Saving the generated graphs in /home/steve.azzolin/DiGress_fork/graphs/sbm_200_resume
Generated graphs Saved. Computing sampling metrics...
Computing sampling metrics between 40 generated graphs and 80 test graphs -- emd computation: False
Building networkx graphs...
Computing degree stats..
Computing spectre stats...
Computing clustering stats...
Computing orbit stats...
Computing accuracy...
Computing all fractions...
Sampling statistics {'spectre': 0.03865571679639457, 'clustering': 0.131896522329898, 'orbit': 0.09912525616760672, 'sbm_acc': 0.0, 'sampling/frac_unique': 1.0, 'sampling/frac_unique_non_iso': 1.0, 'sampling/frac_unic_non_iso_valid': 0.0, 'sampling/frac_non_iso': 1.0}
Done testing.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:             Estimator loss terms ‚ñÅ
wandb:                   batch_test_nll ‚ñÅ
wandb:                       clustering ‚ñÅ
wandb:                         kl prior ‚ñÅ
wandb:                           log_pn ‚ñÅ
wandb:                      loss_term_0 ‚ñÅ
wandb:                            orbit ‚ñÅ
wandb:            sampling/frac_non_iso ‚ñÅ
wandb: sampling/frac_unic_non_iso_valid ‚ñÅ
wandb:             sampling/frac_unique ‚ñÅ
wandb:     sampling/frac_unique_non_iso ‚ñÅ
wandb:                          sbm_acc ‚ñÅ
wandb:                          spectre ‚ñÅ
wandb:                        test/E_kl ‚ñÅ
wandb:                        test/X_kl ‚ñÅ
wandb:                   test/epoch_NLL ‚ñÅ
wandb: 
wandb: Run summary:
wandb:             Estimator loss terms 4843.79492
wandb:                   batch_test_nll 4888.87305
wandb:                       clustering 0.1319
wandb:                           degree 0.53734
wandb:                         kl prior -0.0006
wandb:                           log_pn -44.73009
wandb:                      loss_term_0 -0.34826
wandb:                            orbit 0.09913
wandb:            sampling/frac_non_iso 1.0
wandb: sampling/frac_unic_non_iso_valid 0.0
wandb:             sampling/frac_unique 1.0
wandb:     sampling/frac_unique_non_iso 1.0
wandb:                          sbm_acc 0.0
wandb:                           sbmacc 0.0
wandb:                          spectre 0.03866
wandb:                        test/E_kl 4.86398
wandb:                      test/E_logp nan
wandb:                        test/X_kl 0.0
wandb:                      test/X_logp nan
wandb:                   test/epoch_NLL 4891.8374
wandb: 
wandb: üöÄ View run sbm_200_resume at: https://wandb.ai/mcstewe/graph_ddm_sbm/runs/6954g21b
wandb: Synced 7 W&B file(s), 50 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230726_101214-6954g21b/logs
DONE
Execution lasted 64 minutes
